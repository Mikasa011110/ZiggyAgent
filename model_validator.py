#!/usr/bin/env python3
"""
æ¨¡å‹éªŒè¯è„šæœ¬ - ç”¨äºæ£€æŸ¥è¡¨æƒ…è¯†åˆ«æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½å’Œé…ç½®
"""

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import numpy as np
import cv2
import os

def validate_model():
    """éªŒè¯æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½å’Œé…ç½®"""
    
    print("=== æ¨¡å‹éªŒè¯å¼€å§‹ ===\n")
    
    # 1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = 'ResNet50.pt'
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨!")
        return False
    
    print(f"âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {model_path}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(model_path) / (1024*1024):.1f} MB\n")
    
    # 2. å°è¯•åŠ è½½æ¨¡å‹
    try:
        model = torch.load(model_path, map_location='cpu')
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 3. æ£€æŸ¥æ¨¡å‹ç±»å‹
    if isinstance(model, nn.Module):
        print("âœ… æ¨¡å‹æ˜¯æœ‰æ•ˆçš„PyTorchæ¨¡å—")
    else:
        print(f"âš ï¸  è­¦å‘Š: æ¨¡å‹ç±»å‹ä¸º {type(model)}, å¯èƒ½ä¸æ˜¯æ ‡å‡†çš„PyTorchæ¨¡å‹")
    
    # 4. è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    print("âœ… æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼")
    
    # 5. æµ‹è¯•æ¨¡å‹è¾“å…¥è¾“å‡º
    try:
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(1, 3, 224, 224)
        print(f"ğŸ“Š æµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            test_output = model(test_input)
        
        print(f"ğŸ“Š æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {test_output.shape}")
        print(f"ğŸ“Š è¾“å‡ºç±»åˆ«æ•°: {test_output.shape[1]}")
        
        # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åˆç†
        if test_output.shape[1] == 7:
            print("âœ… è¾“å‡ºç±»åˆ«æ•°æ­£ç¡® (7ç§æƒ…ç»ª)")
        else:
            print(f"âš ï¸  è­¦å‘Š: æœŸæœ›7ä¸ªç±»åˆ«ï¼Œå®é™…å¾—åˆ°{test_output.shape[1]}ä¸ªç±»åˆ«")
        
        # æµ‹è¯•softmax
        probs = torch.nn.functional.softmax(test_output, dim=1)
        prob_sum = torch.sum(probs, dim=1).item()
        print(f"ğŸ“Š Softmaxæ¦‚ç‡å’Œ: {prob_sum:.6f} (åº”è¯¥æ¥è¿‘1.0)")
        
        if 0.99 < prob_sum < 1.01:
            print("âœ… Softmaxè¾“å‡ºæ­£å¸¸")
        else:
            print(f"âš ï¸  è­¦å‘Š: Softmaxæ¦‚ç‡å’Œå¼‚å¸¸: {prob_sum}")
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # 6. æ£€æŸ¥æ¨¡å‹å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
    print(f"   æ€»å‚æ•°æ•°: {total_params:,}")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # 7. æµ‹è¯•é¢„å¤„ç†æµç¨‹
    print(f"\n=== é¢„å¤„ç†æµç¨‹æµ‹è¯• ===")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_img = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)
    test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)
    
    # é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    try:
        pil_img = Image.fromarray(test_img)
        tensor_img = transform(pil_img).unsqueeze(0)
        print(f"âœ… é¢„å¤„ç†æˆåŠŸ")
        print(f"ğŸ“Š é¢„å¤„ç†åå¼ é‡å½¢çŠ¶: {tensor_img.shape}")
        
        # æµ‹è¯•å®Œæ•´æµç¨‹
        with torch.no_grad():
            output = model(tensor_img)
            probs = torch.nn.functional.softmax(output, dim=1)
            confidence, pred_idx = torch.max(probs, 1)
            
        print(f"âœ… å®Œæ•´æ¨ç†æµç¨‹æˆåŠŸ")
        print(f"ğŸ“Š é¢„æµ‹ç±»åˆ«: {pred_idx.item()}")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence.item():.4f}")
        
    except Exception as e:
        print(f"âŒ é¢„å¤„ç†æˆ–æ¨ç†å¤±è´¥: {e}")
        return False
    
    # 8. æƒ…ç»ªæ ‡ç­¾æ˜ å°„æ£€æŸ¥
    print(f"\n=== æƒ…ç»ªæ ‡ç­¾æ˜ å°„ ===")
    emotion_labels = {
        0: "surprise",
        1: "fear", 
        2: "disgust",
        3: "happiness",
        4: "sadness",
        5: "anger",
        6: "neutral"
    }
    
    for idx, emotion in emotion_labels.items():
        print(f"   {idx}: {emotion}")
    
    print(f"\n=== æ¨¡å‹éªŒè¯å®Œæˆ ===")
    print(f"âœ… æ¨¡å‹éªŒè¯é€šè¿‡!")
    return True

def test_with_sample_image():
    """ä½¿ç”¨æ ·æœ¬å›¾åƒæµ‹è¯•æ¨¡å‹"""
    print(f"\n=== æ ·æœ¬å›¾åƒæµ‹è¯• ===")
    
    # åˆ›å»ºä¸€ä¸ªäººè„¸æ ·å¼çš„æµ‹è¯•å›¾åƒ
    test_img = np.ones((200, 200, 3), dtype=np.uint8) * 128  # ç°è‰²èƒŒæ™¯
    
    # æ·»åŠ ç®€å•çš„"äººè„¸"ç‰¹å¾
    # çœ¼ç›
    cv2.circle(test_img, (70, 80), 10, (255, 255, 255), -1)
    cv2.circle(test_img, (130, 80), 10, (255, 255, 255), -1)
    # å˜´å·´ - å¾®ç¬‘
    cv2.ellipse(test_img, (100, 140), (30, 15), 0, 0, 180, (255, 255, 255), 3)
    
    # ä¿å­˜æµ‹è¯•å›¾åƒ
    cv2.imwrite('test_face.jpg', cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR))
    print("ğŸ“¸ åˆ›å»ºæµ‹è¯•å›¾åƒ: test_face.jpg")
    
    # åŠ è½½æ¨¡å‹
    model = torch.load('ResNet50.pt', map_location='cpu')
    model.eval()
    
    # é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    pil_img = Image.fromarray(test_img)
    tensor_img = transform(pil_img).unsqueeze(0)
    
    # æ¨ç†
    with torch.no_grad():
        output = model(tensor_img)
        probs = torch.nn.functional.softmax(output, dim=1)[0]
        
    # æ˜¾ç¤ºç»“æœ
    emotion_labels = {
        0: "surprise", 1: "fear", 2: "disgust", 3: "happiness",
        4: "sadness", 5: "anger", 6: "neutral"
    }
    
    print(f"\nğŸ“Š æµ‹è¯•å›¾åƒé¢„æµ‹ç»“æœ:")
    for i, prob in enumerate(probs):
        print(f"   {emotion_labels[i]}: {prob.item():.4f} ({prob.item()*100:.2f}%)")
    
    confidence, pred_idx = torch.max(probs, 0)
    print(f"\nğŸ¯ æœ€é«˜ç½®ä¿¡åº¦: {emotion_labels[pred_idx.item()]} ({confidence.item()*100:.2f}%)")

if __name__ == "__main__":
    if validate_model():
        test_with_sample_image()
    else:
        print("âŒ æ¨¡å‹éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶") 